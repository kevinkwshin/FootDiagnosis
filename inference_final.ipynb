{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To run this code\n",
    "\n",
    "### 0. Move to Google Colab by pressing this link (https://colab.research.google.com/github/kevinkwshin/FootDiagnosis/blob/main/inference_final.ipynb) \n",
    "\n",
    "### 1. Setting GPU in notebook setting (refer to below image)\n",
    " - ① Click \"Runtime\" in menu\n",
    " - ② Click \"Change runtime type\"\n",
    " - ③ Set Hardware accelerator as \"GPU\" \n",
    " - ④ Click \"Save\"\n",
    " \n",
    " ![image](https://user-images.githubusercontent.com/38489569/204683241-c0c45436-cdb4-499c-8550-5f14cf23e630.png)\n",
    "\n",
    "### 2. Run the code (Keep pressing \"Shift + Enter\" key until the end of the code blocks)\n",
    "- If a warning message appeared, just click \"Run anyway\"\n",
    "- There are 4 session in this codes;\n",
    "- \"1.Load library\"\n",
    "- \"2.Load pretrained model\"\n",
    "- \"3.Prepare test dataset\"\n",
    "- \"4.Inference result\"\n",
    "\n",
    "### 3. If you have additional image to diagnosis (refer to below image)\n",
    "- ① Click folder button on the bottom of left sidebar\n",
    "- ② Click \"FootDiagnosis\" to expand the tree structure\n",
    "- ③ Drag and drop your foot X-ray images to \"FootDiagnosis/input_data\"\n",
    "- ④ Run the code from \"3.Prepare test dataset\" (By using \"Shift + Enter\")\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/38489569/204684189-e7894aec-b1d5-41cb-ae2e-2090c7422fd0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/kevinkwshin/FootDiagnosis/\n",
    "%cd FootDiagnosis/\n",
    "\n",
    "!pip install -U pydicom nibabel monai==0.8.0 kornia pytorch_lightning\n",
    "!pip install --upgrade https://github.com/VincentStimper/mclahe/archive/numpy.zip\n",
    "!pip install --upgrade gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "!nvidia-smi\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, natsort\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "\n",
    "import skimage\n",
    "import skimage.morphology\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import kornia\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mclahe\n",
    "\n",
    "# axis method\n",
    "# 1. PCA\n",
    "# 2. Minimum Rotational inertia\n",
    "# 3. Ellipse\n",
    "\n",
    "def visualize(**images):\n",
    "    \"\"\"Plot images in one row.\"\"\"\n",
    "    angles = list()\n",
    "    \n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(32, 16))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        if i==0 and image.shape[0] == 3:\n",
    "            image_main = image.permute(1,2,0).numpy()#.int()\n",
    "        if torch.is_tensor(image) and image.shape[0] == 3:\n",
    "            image = image.permute(1,2,0).numpy()#.int()\n",
    "        else:\n",
    "            try:\n",
    "                image = image.numpy()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        # plt.title()\n",
    "        plt.imshow(image_main,cmap='gray')        \n",
    "        plt.imshow(image,cmap='gray',alpha=0.4)\n",
    "        if i == 1:\n",
    "            head = head_direction(image)\n",
    "        if i>=1:           \n",
    "            major = True if i <=4 else False\n",
    "            clockwise_plus = True if i==1 else False\n",
    "            x0,y0,angle = PCA_axis(image,major)\n",
    "            # x0,y0,angle = inertia_axis(image,major)\n",
    "            plt.title(' '.join(name.split('_')).title()+'_PCA : {:.2f} degrees'.format(refine_degree(angle,head,clockwise_plus=clockwise_plus)))\n",
    "            image = kornia.morphology.opening(torch.tensor(image).unsqueeze(0).unsqueeze(0),torch.ones(5,5))\n",
    "            image = image.squeeze()\n",
    "            draw_axis(image_main, image, x0, y0, angle)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def draw_axis(image, mask, x0, y0, radian_degree):\n",
    "    \"\"\"\n",
    "    radian_degree\n",
    "    \"\"\"\n",
    "    length = 320\n",
    "    \n",
    "    x1 = x0 + math.cos(radian_degree) * 0.5 * length\n",
    "    y1 = y0 + math.sin(radian_degree) * 0.5 * length\n",
    "    x2 = x0 - math.cos(radian_degree) * 0.5 * length\n",
    "    y2 = y0 - math.sin(radian_degree) * 0.5 * length\n",
    "    x3 = x0 + math.sin(radian_degree) * 0.5 * length\n",
    "    y3 = y0 - math.cos(radian_degree) * 0.5 * length\n",
    "    x4 = x0 - math.sin(radian_degree) * 0.5 * length\n",
    "    y4 = y0 + math.cos(radian_degree) * 0.5 * length\n",
    "\n",
    "    plt.imshow(image,cmap='gray')\n",
    "    plt.imshow(mask,cmap='gray',alpha=0.4)\n",
    "    plt.contour(mask,colors='#FD8A02',alpha=.5)\n",
    "    angle = - np.tan((y0 - y2) / (x0 - x2))\n",
    "    plt.plot((x0, x1), (y0, y1), '#01686D', linewidth=3)\n",
    "    plt.plot((x0, x2), (y0, y2), '#01686D', linewidth=3)\n",
    "    plt.plot(x0, y0, '.g', markersize=15)\n",
    "    \n",
    "\n",
    "def raw_moment(data, iord, jord):\n",
    "    nrows, ncols = data.shape\n",
    "    y, x = np.mgrid[:nrows, :ncols]\n",
    "    data = data * x**iord * y**jord\n",
    "    return data.sum() \n",
    "\n",
    "def inertia_axis(data, major):\n",
    "    data_sum = data.sum()\n",
    "    m10 = raw_moment(data, 1, 0)\n",
    "    m01 = raw_moment(data, 0, 1)\n",
    "    x_bar = m10 / data_sum\n",
    "    y_bar = m01 / data_sum\n",
    "    u11 = (raw_moment(data, 1, 1) - x_bar * m01) / data_sum\n",
    "    u20 = (raw_moment(data, 2, 0) - x_bar * m10) / data_sum\n",
    "    u02 = (raw_moment(data, 0, 2) - y_bar * m01) / data_sum\n",
    "    \n",
    "    if major == True:\n",
    "        angle = 0.5 * np.arctan(2 * u11 / (u20 - u02))\n",
    "    else:\n",
    "        angle = 0.5 * np.arctan(2 * u11 / (u20 - u02)) # + np.pi/2\n",
    "    \n",
    "    return x_bar, y_bar, angle\n",
    "\n",
    "def ellipse_axis(image, major=True):\n",
    "    try:\n",
    "        image = image.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    image = image.astype(np.uint8)\n",
    "    regions = regionprops(image)\n",
    "    for props in regions:\n",
    "        y0, x0 = props.centroid\n",
    "        orientation = props.orientation\n",
    "        x1 = x0 + math.sin(orientation) * 0.5 * 300\n",
    "        y1 = y0 + math.cos(orientation) * 0.5 * 300\n",
    "        x2 = x0 - math.sin(orientation) * 0.5 * 300\n",
    "        y2 = y0 - math.cos(orientation) * 0.5 * 300\n",
    "        x3 = x0 + math.cos(orientation) * 0.5 * 150\n",
    "        y3 = y0 - math.sin(orientation) * 0.5 * 150\n",
    "        x4 = x0 - math.cos(orientation) * 0.5 * 150\n",
    "        y4 = y0 + math.sin(orientation) * 0.5 * 150\n",
    "        \n",
    "        if major:\n",
    "            angle = np.tan((y0 - y2) / (x0 - x2))\n",
    "        else:\n",
    "            angle = np.tan((y0 - y3) / (x0 - x3))\n",
    "\n",
    "    return x0, y0, angle\n",
    "\n",
    "def PCA_axis(mask_2d,major=True):\n",
    "    \n",
    "    mask_2d = np.rot90(mask_2d,2)\n",
    "    mask_2d = np.flip(mask_2d)\n",
    "    b= np.nonzero(mask_2d == 1)\n",
    "    b = np.array(b)\n",
    "    b = np.transpose(b) \n",
    "    b = np.flip(b) \n",
    "    X = b\n",
    "    \n",
    "#     # visualize\n",
    "#     plt.axis('equal')\n",
    "#     plt.scatter(X[:,0],X[:,1]);    \n",
    "\n",
    "    pca=PCA(2)\n",
    "    pca.fit(X)\n",
    "\n",
    "#     print(\"Principal axes:\", pca.components_)\n",
    "#     print(\"Explained variance:\", pca.explained_variance_)\n",
    "#     print(\"Principal axes angle:\",angle)\n",
    "#     print(\"Mean:\", pca.mean_)\n",
    "\n",
    "    if major == True:\n",
    "        angle = np.arctan(pca.components_[0][1]/pca.components_[0][0])\n",
    "    else:\n",
    "        angle = np.arctan(pca.components_[0][1]/pca.components_[0][0]) - np.pi/2\n",
    "        \n",
    "    x0,y0 = pca.mean_\n",
    "    return x0, y0, angle\n",
    "\n",
    "def refine_degree(radian, head, clockwise_plus=True):\n",
    "    while radian <= -np.pi/2:\n",
    "        radian += np.pi\n",
    "    while radian >= np.pi/2:\n",
    "        radian -= np.pi\n",
    "    \n",
    "    degree = np.degrees(radian)\n",
    "\n",
    "    if head=='left' and clockwise_plus==True:\n",
    "        return degree\n",
    "    elif head=='right' and clockwise_plus==True:\n",
    "        return -degree\n",
    "    elif head=='left' and clockwise_plus==False:\n",
    "        return -degree\n",
    "    elif head=='right' and clockwise_plus==False:\n",
    "        return degree\n",
    "    \n",
    "def head_direction(mask_1_2d):\n",
    "    y,x = mask_1_2d.shape  \n",
    "    x0,y0,_ = inertia_axis(mask_1_2d,True)\n",
    "    ratio = x0/x\n",
    "    if ratio > 0.5: \n",
    "        head = 'left'\n",
    "    else:\n",
    "        head = 'right'\n",
    "    return head\n",
    "\n",
    "def clahe(img, dim = -1, adaptive_hist_range=False):\n",
    "    \"\"\"\n",
    "    input 1 numpy shape image (H x W x (D) x C)\n",
    "    \"\"\"\n",
    "    temp = np.zeros_like(img)\n",
    "    if dim == -1:\n",
    "        for idx in range(temp.shape[-1]):\n",
    "            temp[...,idx] = mclahe.mclahe(img[...,idx], kernel_size=None, n_bins=128, clip_limit=0.04, adaptive_hist_range=adaptive_hist_range)\n",
    "    elif dim == 0:\n",
    "        for idx in range(temp.shape[0]):\n",
    "            temp[idx] = mclahe.mclahe(img[idx], kernel_size=None, n_bins=128, clip_limit=0.04, adaptive_hist_range=adaptive_hist_range)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class REBNCONV(nn.Module):\n",
    "    def __init__(self,in_ch=3,out_ch=3,dirate=1):\n",
    "        super(REBNCONV,self).__init__()\n",
    "\n",
    "        self.conv_s1 = nn.Conv2d(in_ch,out_ch,3,padding=1*dirate,dilation=1*dirate)\n",
    "        self.bn_s1 = nn.BatchNorm2d(out_ch)\n",
    "        self.relu_s1 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "        xout = self.relu_s1(self.bn_s1(self.conv_s1(hx)))\n",
    "\n",
    "        return xout\n",
    "\n",
    "## upsample tensor 'src' to have the same spatial size with tensor 'tar'\n",
    "def _upsample_like(src,tar):\n",
    "\n",
    "    src = F.upsample(src,size=tar.shape[2:],mode='bilinear')\n",
    "\n",
    "    return src\n",
    "\n",
    "\n",
    "### RSU-7 ###\n",
    "class RSU7(nn.Module):#UNet07DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU7,self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool5 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv7 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
    "\n",
    "        self.rebnconv6d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "        hx = self.pool3(hx3)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx)\n",
    "        hx = self.pool4(hx4)\n",
    "\n",
    "        hx5 = self.rebnconv5(hx)\n",
    "        hx = self.pool5(hx5)\n",
    "\n",
    "        hx6 = self.rebnconv6(hx)\n",
    "\n",
    "        hx7 = self.rebnconv7(hx6)\n",
    "\n",
    "        hx6d =  self.rebnconv6d(torch.cat((hx7,hx6),1))\n",
    "        hx6dup = _upsample_like(hx6d,hx5)\n",
    "\n",
    "        hx5d =  self.rebnconv5d(torch.cat((hx6dup,hx5),1))\n",
    "        hx5dup = _upsample_like(hx5d,hx4)\n",
    "\n",
    "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
    "        hx4dup = _upsample_like(hx4d,hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "### RSU-6 ###\n",
    "class RSU6(nn.Module):#UNet06DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU6,self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
    "\n",
    "        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "        hx = self.pool3(hx3)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx)\n",
    "        hx = self.pool4(hx4)\n",
    "\n",
    "        hx5 = self.rebnconv5(hx)\n",
    "\n",
    "        hx6 = self.rebnconv6(hx5)\n",
    "\n",
    "\n",
    "        hx5d =  self.rebnconv5d(torch.cat((hx6,hx5),1))\n",
    "        hx5dup = _upsample_like(hx5d,hx4)\n",
    "\n",
    "        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n",
    "        hx4dup = _upsample_like(hx4d,hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "### RSU-5 ###\n",
    "class RSU5(nn.Module):#UNet05DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU5,self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
    "\n",
    "        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "        hx = self.pool3(hx3)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx)\n",
    "\n",
    "        hx5 = self.rebnconv5(hx4)\n",
    "\n",
    "        hx4d = self.rebnconv4d(torch.cat((hx5,hx4),1))\n",
    "        hx4dup = _upsample_like(hx4d,hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "### RSU-4 ###\n",
    "class RSU4(nn.Module):#UNet04DRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU4,self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
    "\n",
    "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx = self.pool1(hx1)\n",
    "\n",
    "        hx2 = self.rebnconv2(hx)\n",
    "        hx = self.pool2(hx2)\n",
    "\n",
    "        hx3 = self.rebnconv3(hx)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "### RSU-4F ###\n",
    "class RSU4F(nn.Module):#UNet04FRES(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
    "        super(RSU4F,self).__init__()\n",
    "\n",
    "        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n",
    "\n",
    "        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n",
    "        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=2)\n",
    "        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=4)\n",
    "\n",
    "        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=8)\n",
    "\n",
    "        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=4)\n",
    "        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=2)\n",
    "        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        hxin = self.rebnconvin(hx)\n",
    "\n",
    "        hx1 = self.rebnconv1(hxin)\n",
    "        hx2 = self.rebnconv2(hx1)\n",
    "        hx3 = self.rebnconv3(hx2)\n",
    "\n",
    "        hx4 = self.rebnconv4(hx3)\n",
    "\n",
    "        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n",
    "        hx2d = self.rebnconv2d(torch.cat((hx3d,hx2),1))\n",
    "        hx1d = self.rebnconv1d(torch.cat((hx2d,hx1),1))\n",
    "\n",
    "        return hx1d + hxin\n",
    "\n",
    "\n",
    "##### U^2-Net ####\n",
    "class U2NET(nn.Module):\n",
    "\n",
    "    def __init__(self,in_ch=1,out_ch=5):\n",
    "        super(U2NET,self).__init__()\n",
    "\n",
    "        self.stage1 = RSU7(in_ch,32,64)\n",
    "        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage2 = RSU6(64,32,128)\n",
    "        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage3 = RSU5(128,64,256)\n",
    "        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage4 = RSU4(256,128,512)\n",
    "        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage5 = RSU4F(512,256,512)\n",
    "        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage6 = RSU4F(512,256,512)\n",
    "\n",
    "        # decoder\n",
    "        self.stage5d = RSU4F(1024,256,512)\n",
    "        self.stage4d = RSU4(1024,128,256)\n",
    "        self.stage3d = RSU5(512,64,128)\n",
    "        self.stage2d = RSU6(256,32,64)\n",
    "        self.stage1d = RSU7(128,16,64)\n",
    "\n",
    "        self.side1 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side2 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side3 = nn.Conv2d(128,out_ch,3,padding=1)\n",
    "        self.side4 = nn.Conv2d(256,out_ch,3,padding=1)\n",
    "        self.side5 = nn.Conv2d(512,out_ch,3,padding=1)\n",
    "        self.side6 = nn.Conv2d(512,out_ch,3,padding=1)\n",
    "\n",
    "        self.outconv = nn.Conv2d(6*out_ch,out_ch,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        #stage 1\n",
    "        hx1 = self.stage1(hx)\n",
    "        hx = self.pool12(hx1)\n",
    "\n",
    "        #stage 2\n",
    "        hx2 = self.stage2(hx)\n",
    "        hx = self.pool23(hx2)\n",
    "\n",
    "        #stage 3\n",
    "        hx3 = self.stage3(hx)\n",
    "        hx = self.pool34(hx3)\n",
    "\n",
    "        #stage 4\n",
    "        hx4 = self.stage4(hx)\n",
    "        hx = self.pool45(hx4)\n",
    "\n",
    "        #stage 5\n",
    "        hx5 = self.stage5(hx)\n",
    "        hx = self.pool56(hx5)\n",
    "\n",
    "        #stage 6\n",
    "        hx6 = self.stage6(hx)\n",
    "        hx6up = _upsample_like(hx6,hx5)\n",
    "\n",
    "        #-------------------- decoder --------------------\n",
    "        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n",
    "        hx5dup = _upsample_like(hx5d,hx4)\n",
    "\n",
    "        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n",
    "        hx4dup = _upsample_like(hx4d,hx3)\n",
    "\n",
    "        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "\n",
    "        #side output\n",
    "        d1 = self.side1(hx1d)\n",
    "\n",
    "        d2 = self.side2(hx2d)\n",
    "        d2 = _upsample_like(d2,d1)\n",
    "\n",
    "        d3 = self.side3(hx3d)\n",
    "        d3 = _upsample_like(d3,d1)\n",
    "\n",
    "        d4 = self.side4(hx4d)\n",
    "        d4 = _upsample_like(d4,d1)\n",
    "\n",
    "        d5 = self.side5(hx5d)\n",
    "        d5 = _upsample_like(d5,d1)\n",
    "\n",
    "        d6 = self.side6(hx6)\n",
    "        d6 = _upsample_like(d6,d1)\n",
    "\n",
    "        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n",
    "\n",
    "        return F.sigmoid(d0), F.sigmoid(d1), F.sigmoid(d2), F.sigmoid(d3), F.sigmoid(d4), F.sigmoid(d5), F.sigmoid(d6)\n",
    "\n",
    "### U^2-Net small ###\n",
    "class U2NETP(nn.Module):\n",
    "\n",
    "    def __init__(self,in_ch=3,out_ch=1):\n",
    "        super(U2NETP,self).__init__()\n",
    "\n",
    "        self.stage1 = RSU7(in_ch,16,64)\n",
    "        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage2 = RSU6(64,16,64)\n",
    "        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage3 = RSU5(64,16,64)\n",
    "        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage4 = RSU4(64,16,64)\n",
    "        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage5 = RSU4F(64,16,64)\n",
    "        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n",
    "\n",
    "        self.stage6 = RSU4F(64,16,64)\n",
    "\n",
    "        # decoder\n",
    "        self.stage5d = RSU4F(128,16,64)\n",
    "        self.stage4d = RSU4(128,16,64)\n",
    "        self.stage3d = RSU5(128,16,64)\n",
    "        self.stage2d = RSU6(128,16,64)\n",
    "        self.stage1d = RSU7(128,16,64)\n",
    "\n",
    "        self.side1 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side2 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side3 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side4 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side5 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "        self.side6 = nn.Conv2d(64,out_ch,3,padding=1)\n",
    "\n",
    "        self.outconv = nn.Conv2d(6*out_ch,out_ch,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        hx = x\n",
    "\n",
    "        #stage 1\n",
    "        hx1 = self.stage1(hx)\n",
    "        hx = self.pool12(hx1)\n",
    "\n",
    "        #stage 2\n",
    "        hx2 = self.stage2(hx)\n",
    "        hx = self.pool23(hx2)\n",
    "\n",
    "        #stage 3\n",
    "        hx3 = self.stage3(hx)\n",
    "        hx = self.pool34(hx3)\n",
    "\n",
    "        #stage 4\n",
    "        hx4 = self.stage4(hx)\n",
    "        hx = self.pool45(hx4)\n",
    "\n",
    "        #stage 5\n",
    "        hx5 = self.stage5(hx)\n",
    "        hx = self.pool56(hx5)\n",
    "\n",
    "        #stage 6\n",
    "        hx6 = self.stage6(hx)\n",
    "        hx6up = _upsample_like(hx6,hx5)\n",
    "\n",
    "        #decoder\n",
    "        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n",
    "        hx5dup = _upsample_like(hx5d,hx4)\n",
    "\n",
    "        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n",
    "        hx4dup = _upsample_like(hx4d,hx3)\n",
    "\n",
    "        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n",
    "        hx3dup = _upsample_like(hx3d,hx2)\n",
    "\n",
    "        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n",
    "        hx2dup = _upsample_like(hx2d,hx1)\n",
    "\n",
    "        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n",
    "\n",
    "\n",
    "        #side output\n",
    "        d1 = self.side1(hx1d)\n",
    "\n",
    "        d2 = self.side2(hx2d)\n",
    "        d2 = _upsample_like(d2,d1)\n",
    "\n",
    "        d3 = self.side3(hx3d)\n",
    "        d3 = _upsample_like(d3,d1)\n",
    "\n",
    "        d4 = self.side4(hx4d)\n",
    "        d4 = _upsample_like(d4,d1)\n",
    "\n",
    "        d5 = self.side5(hx5d)\n",
    "        d5 = _upsample_like(d5,d1)\n",
    "\n",
    "        d6 = self.side6(hx6)\n",
    "        d6 = _upsample_like(d6,d1)\n",
    "\n",
    "        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n",
    "\n",
    "        return F.sigmoid(d0), F.sigmoid(d1), F.sigmoid(d2), F.sigmoid(d3), F.sigmoid(d4), F.sigmoid(d5), F.sigmoid(d6)\n",
    "    \n",
    "bce_loss = nn.BCELoss(size_average=True)\n",
    "\n",
    "def muti_bce_loss_fusion(yhat, labels_v):\n",
    "    d0, d1, d2, d3, d4, d5, d6 = yhat\n",
    "    loss0 = bce_loss(d0,labels_v)\n",
    "    loss1 = bce_loss(d1,labels_v)\n",
    "    loss2 = bce_loss(d2,labels_v)\n",
    "    loss3 = bce_loss(d3,labels_v)\n",
    "    loss4 = bce_loss(d4,labels_v)\n",
    "    loss5 = bce_loss(d5,labels_v)\n",
    "    loss6 = bce_loss(d6,labels_v)\n",
    "\n",
    "    loss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6\n",
    "    # print(\"l0: %3f, l1: %3f, l2: %3f, l3: %3f, l4: %3f, l5: %3f, l6: %3f\\n\"%(loss0.data.item(),loss1.data.item(),loss2.data.item(),loss3.data.item(),loss4.data.item(),loss5.data.item(),loss6.data.item()))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def bn2group(module):\n",
    "    num_groups = 16 # hyper_parameter of GroupNorm\n",
    "    # num_groups = 8 # hyper_parameter of GroupNorm\n",
    "    module_output = module\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        if module.num_features/num_groups <1:\n",
    "            module_output = torch.nn.GroupNorm(1,\n",
    "                                           module.num_features,\n",
    "                                           module.eps, \n",
    "                                           module.affine,\n",
    "                                          )\n",
    "        else:\n",
    "            module_output = torch.nn.GroupNorm(num_groups,\n",
    "                               module.num_features,\n",
    "                               module.eps, \n",
    "                               module.affine,\n",
    "                                          )\n",
    "\n",
    "        if module.affine:\n",
    "            with torch.no_grad():\n",
    "                module_output.weight = module.weight\n",
    "                module_output.bias = module.bias\n",
    "        module_output.running_mean = module.running_mean\n",
    "        module_output.running_var = module.running_var\n",
    "        module_output.num_batches_tracked = module.num_batches_tracked\n",
    "        \n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig\n",
    "\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(name, bn2group(child))\n",
    "\n",
    "    del module\n",
    "    return module_output\n",
    "\n",
    "net = U2NET(in_ch=3,out_ch=5)\n",
    "net = bn2group(net)\n",
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import *\n",
    "\n",
    "class Segmentor(pl.LightningModule):\n",
    "    def __init__(self, network, lossfn, metricfn, experiment_name):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = network\n",
    "        self.lossfn = lossfn\n",
    "        self.metricfn = metricfn\n",
    "        self.experiment_name = experiment_name\n",
    "        self.best_val_loss_epoch = np.inf            \n",
    "        self.best_valid_epoch = 0\n",
    "        \n",
    "        if isinstance(lossfn,list) and isinstance(metricfn,list):\n",
    "            assert len(lossfn) == len(metricfn)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        \n",
    "    def pipeline(self, batch, sw=False, plot=False):\n",
    "        x, y = batch['image'].float(), batch['seg'].float()\n",
    "        if not sw:\n",
    "            yhat = self.net(x)\n",
    "            loss = muti_bce_loss_fusion(yhat, y)\n",
    "            yhat = yhat[0]\n",
    "            metric = torch.mean(metricfn(yhat,y,))\n",
    "        else:\n",
    "            def predictor(x, return_idx = 0): # in case of prediction is type of list\n",
    "                result = self.net(x)\n",
    "                if isinstance(result, list) or isinstance(result, tuple):\n",
    "                    return result[return_idx]\n",
    "                else:\n",
    "                    return resul\n",
    "            yhat = sliding_window_inference(x, roi_size=(512,1024), sw_batch_size=2, predictor=predictor)\n",
    "            loss = bce_loss(yhat,y)\n",
    "            metric = torch.mean(metricfn(yhat,y,))\n",
    "            # from scipy.ndimage import label, binary_closing\n",
    "            # for i in range(yhat.shape[1]):\n",
    "            #     for j in range(yhat.shape[1]):\n",
    "            #         yhat[i,j] = binary_closing(yhat[i,j], structure=np.ones(13,13)) # closing of R-peak\n",
    "    \n",
    "        if plot:\n",
    "            for idx in range(len(x)):\n",
    "                visualize(image=x[idx].cpu(), mask1=y[idx,0].cpu().detach().numpy(), mask2=y[idx,1].cpu().detach().numpy(), mask3=y[idx,2].cpu().detach().numpy(), mask4=y[idx,3].cpu().detach().numpy(), mask5=y[idx,4].cpu().detach().numpy())\n",
    "                visualize(image=x[idx].cpu(), mask1=yhat[idx,0].cpu().detach().numpy(), mask2=yhat[idx,1].cpu().detach().numpy(), mask3=yhat[idx,2].cpu().detach().numpy(), mask4=yhat[idx,3].cpu().detach().numpy(), mask5=yhat[idx,4].cpu().detach().numpy())\n",
    "        return loss, metric\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=.9)\n",
    "        # return optimizer\n",
    "        return {'optimizer': optimizer,\n",
    "                'lr_scheduler': {'scheduler': scheduler, 'monitor': 'val_loss'}}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, metric = self.pipeline(batch, sw=False, plot=False)\n",
    "        self.log('loss', loss, on_step=True, on_epoch=True, prog_bar=True,)\n",
    "        if isinstance(metric,list):\n",
    "            self.log('f1', metric[0], on_step=True, on_epoch=True, prog_bar=True,)\n",
    "            self.log('acc', metric[1], on_step=True, on_epoch=True, prog_bar=True,)\n",
    "        else:\n",
    "            self.log('f1', metric, on_step=True, on_epoch=True, prog_bar=True,)            \n",
    "        return loss\n",
    "      \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, metric = self.pipeline(batch, sw=True, plot=False)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True,)\n",
    "        if isinstance(metric,list):\n",
    "            self.log('val_f1', metric[0], on_epoch=True, prog_bar=True,)\n",
    "            self.log('val_acc', metric[1], on_epoch=True, prog_bar=True,)\n",
    "        else:\n",
    "            self.log('val_f1', metric, on_epoch=True, prog_bar=True,)            \n",
    "        return {\"val_loss\":loss}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, metric = self.pipeline(batch, sw=True, plot=False)\n",
    "        self.log('test_loss', loss, on_step=True, on_epoch=True, prog_bar=True,)\n",
    "        if isinstance(metric,list):\n",
    "            self.log('test_f1', metric[0], on_epoch=True, prog_bar=True,)\n",
    "            self.log('test_acc', metric[1], on_epoch=True, prog_bar=True,)\n",
    "        else:\n",
    "            self.log('test_f1', metric, on_epoch=True, prog_bar=True,)            \n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_losses = []\n",
    "        for output in outputs:\n",
    "            val_losses.append(output[\"val_loss\"].cpu().detach().numpy())\n",
    "        val_loss_epoch = np.mean(val_losses)\n",
    "        # self.log('val_loss_epoch', val_loss_epoch)\n",
    "        \n",
    "        if val_loss_epoch < self.best_val_loss_epoch and self.current_epoch>0:\n",
    "            self.best_valid_epoch = self.current_epoch\n",
    "            self.best_val_loss_epoch = val_loss_epoch             \n",
    "        print(\n",
    "            f\"current epoch: {self.current_epoch}, \"\n",
    "            f\"current epoch val_loss: {val_loss_epoch:.4f}, \"\n",
    "            f\"best epoch val_loss: {self.best_val_loss_epoch:.4f}, \"\n",
    "            f\"at epoch: {self.best_valid_epoch}, \" \n",
    "        )\n",
    "                \n",
    "import torchmetrics\n",
    "lossfn = monai.losses.DiceFocalLoss(to_onehot_y=False)\n",
    "\n",
    "# metricfn = torchmetrics.functional.dice_score\n",
    "metricfn = torchmetrics.functional.dice_score\n",
    "# metricfn = sklearn.metrics.f1_score\n",
    "\n",
    "# model\n",
    "experiment_name = 'U2NET'\n",
    "model = Segmentor(network=net, lossfn=lossfn, metricfn=metricfn, experiment_name=experiment_name,)\n",
    "\n",
    "import gdown\n",
    "url = \"https://drive.google.com/uc?id=190Xgq70AvvORK-rVZbKpJK5Fx4uIXkYQ\"\n",
    "output = \"weight.ckpt\"\n",
    "gdown.download(url, output, quiet=False, verify=True)\n",
    "\n",
    "model.load_from_checkpoint(network=net, lossfn=lossfn, metricfn=metricfn, experiment_name=experiment_name,checkpoint_path='weight.ckpt')\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare test dataset\n",
    "\n",
    "- Load files from \"./FootDiagnosis/input_data/\" folder\n",
    "- The dataset we provide were from LERA dataset (https://aimi.stanford.edu/lera-lower-extremity-radiographs), which were external test dataset of our study \n",
    "- If you have Foot X-ray to analyze, upload file to \"input_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_inference(folder_name): \n",
    "    x_etest = natsort.natsorted(glob.glob(os.path.join(folder_name,'*.png')))\n",
    "    y_etest = natsort.natsorted(glob.glob(os.path.join(folder_name,'*.png')))\n",
    "\n",
    "    etest_files = [{\"image\": img, \"seg\": seg, \"fname\": img} for img, seg in zip(x_etest, y_etest)]\n",
    "    for e in etest_files:\n",
    "        print(e)\n",
    "    return etest_files\n",
    "\n",
    "class test_dataset() : \n",
    "    def __init__(self, data) :\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.data[idx]['image']\n",
    "        seg_file = self.data[idx]['seg']\n",
    "        \n",
    "        image = cv2.imread(image_file)\n",
    "        seg = cv2.imread(seg_file) \n",
    "\n",
    "        image = cv2.resize(image, (1024, int((image.shape[0]/image.shape[1])*1024)) , interpolation = cv2.INTER_AREA)\n",
    "        seg = cv2.resize(seg, (1024, int((image.shape[0]/image.shape[1])*1024)) , interpolation = cv2.INTER_AREA)\n",
    "      \n",
    "        seg = np.zeros((seg.shape[0], seg.shape[1],5)) if len(np.unique(seg))>=3 else seg \n",
    "        \n",
    "        image = np.moveaxis(image,-1,0) \n",
    "        seg = np.moveaxis(seg,-1,0)\n",
    "        \n",
    "        image = image/255\n",
    "        \n",
    "        image = clahe(image,0)\n",
    "        image = torch.Tensor(image)#.unsqueeze(0) \n",
    "        seg = torch.Tensor(seg)#.unsqueeze(0)\n",
    "        \n",
    "        return {'image':image ,'seg':seg, 'fname':image_file}\n",
    "    \n",
    "    \n",
    "etest_files = seg_inference(\"input_data\")\n",
    "\n",
    "etest_ds = test_dataset(data=etest_files)\n",
    "etest_loader = DataLoader(etest_ds, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "iterator = iter(etest_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(etest_loader) : \n",
    "    x = batch['image']\n",
    "    y = batch['seg']\n",
    "    fname = batch['fname']\n",
    "    plt.imshow(x[0,0],cmap='gray')\n",
    "    plt.title(f'Original foot X-ray : {fname[0]}')\n",
    "    plt.show()\n",
    "    with torch.no_grad():\n",
    "        yhat = net(x.cuda()) \n",
    "    min_height = 2000 \n",
    "    max_height = 0 \n",
    "    image_height = x[0,0].shape[0]\n",
    "\n",
    "    for idx in range(5) :     \n",
    "        local_min = (yhat[0][0,idx]==True).nonzero(as_tuple=True)[0].median().item() \n",
    "        local_max = (yhat[0][0,idx]==True).nonzero(as_tuple=True)[0].median().item() \n",
    "        min_height = min(min_height, local_min)\n",
    "        max_height = max(max_height, local_max)\n",
    "    \n",
    "    center_height = (min_height+max_height)//2\n",
    "    # print(\"Final min_height is \", min_height)\n",
    "    # print(\"Final max_height is \", max_height)\n",
    "    # print(\"Final center_height is \", center_height)\n",
    "\n",
    "    top = center_height-256 if center_height>=256 else 0\n",
    "    bottom = center_height+256 if center_height+256<x.shape[2] else x.shape[2]\n",
    "    x_resize = x[:,:,top:bottom,:]\n",
    "    pad = 512 - x_resize.shape[2]\n",
    "    if pad!=0:\n",
    "        top = pad//2\n",
    "        bottom = pad-top\n",
    "        x_resize = F.pad(x_resize,(0, 0, top, bottom))\n",
    "    plt.imshow(x_resize[0,0])\n",
    "    plt.show()\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        yhat = net(x_resize.cuda())\n",
    "    yhat = yhat[0].cpu().detach().numpy().round()\n",
    "    yhat = yhat.astype(bool)\n",
    "    \n",
    "    for i in range(5):            \n",
    "        yhat[0,i] = skimage.morphology.remove_small_objects(yhat[0,i], min_size=500, connectivity=2)\n",
    "    yhat = yhat.astype(int)\n",
    "    visualize(image=x_resize[0].cpu(), mask1=yhat[0,0], mask2=yhat[0,1], mask3=yhat[0,2], mask4=yhat[0,3], mask5=yhat[0,4])\n",
    "        \n",
    "    print(\"*\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
